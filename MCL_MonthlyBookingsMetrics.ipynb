{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea88764-1000-47a2-b6e6-e1afc6cacdff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Monthly Stats and Metrics for Scott Media Creation Lab's Spaces and Equipment\n",
    "\n",
    "_by Kris Joseph, kjo@yorku.ca_\n",
    "\n",
    "This script is intended to be run monthly to grab key data points for metrics and stats. It should be run AFTER the end of the month (e.g. run the script for July AFTER August 1 to ensure there's a full month of data in the system).\n",
    "\n",
    "Multiple outputs will be generated:\n",
    "1. \"Raw\" equipment data, in a file called (yyyy-mm-dd)_equip.csv\n",
    "    \n",
    "2. \"Raw\" spaces data, in a file called (yyyy-mm-dd)_space.csv\n",
    "    \n",
    "3. Final metrics data (for input into DSI's tracking spreadsheet) for both modules:\n",
    "    - (yyyy-mm-dd)_equipment_finalStats.csv: equipment data only\n",
    "    - (yyyy-mm-dd)_space_finalStats.csv: spaces data only\n",
    "    - (yyyy-mm-dd)overall_finalStats.csv: ALL data, ready to copy into spreadsheet\n",
    "    \n",
    "*IMPORTANT*\n",
    "This script is totally tied to the format of the data tracking spreadsheet (i.e. the number of columns, in the order generated here, are intended to match the layout of the spreadsheet so that when a data row is added it just has to be pasted in and all the columns will line up properly. As a result, any changes to the column order in this script OR in the DSI tracking sheet must be made in both places (here and in the spreadsheet).\n",
    "\n",
    "#### GENERAL NOTES ON THIS IMPLEMENTATION\n",
    "\n",
    "1. Want to revise this so that a month and year can be input on the command line to grab data easily\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b505ca1-2198-4e43-bfe7-f04b63862091",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set the value for the month that stats are needed for\n",
    "\n",
    "To run this script, the only thing you should have to change is the \"datadate\" field below. Enter in the form yyyy-mm-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c26cc0b-53d1-4685-b029-8d50cc21e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, csv, calendar, datetime, math, collections, hashlib, os, shutil\n",
    "from os.path import exists\n",
    "from datetime import *\n",
    "import pandas as pd\n",
    "\n",
    "## INPUT variable\n",
    "# Set this to the year and month for which data will be gathered, in yyy-mm-dd format. dd should always be 01\n",
    "# This is also the date format LibCal's API expects for the API calls\n",
    "datadate = \"2024-05-01\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a15a1-d92a-48b9-b11d-20a28b4790f6",
   "metadata": {},
   "source": [
    "## Variable initializations and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb1a0c74-4c85-48ec-9334-8b1131190c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our outputData dictionary. This dictionary is gonna have a TON of data points in it eventually....\n",
    "equipmentOutputData = {}\n",
    "spacesOutputData = {}\n",
    "\n",
    "# We'll need an accurate number of days in the month to make a proper call to the API (get 30 days of data for some months, 31 for others, and 28 for one special month)\n",
    "[year, month, day] = datadate.split(\"-\")\n",
    "daysInMonth = calendar.monthrange(int(year), int(month))[1]\n",
    "\n",
    "# Make backups of old \"overall users\" data, since calculating first-time users\n",
    "# means comparing the previous month to the current one. If we don't make a backup, and\n",
    "# these scripts fail for some reason, future runs will always show \"first time users\" as 0 because\n",
    "# the \"existingUsers\" data files will already have been updated\n",
    "fileExtension = \".txt\"\n",
    "fileDirectory = \"data/\"\n",
    "for file in [\"existingSpaceUsers\", \"existingEquipmentUsers\", \"existingOverallUsers\"]:\n",
    "    if not exists(fileDirectory + file + \"-\" + str(year) + str(month) + fileExtension):\n",
    "        print(\"Nope\")\n",
    "        shutil.copyfile(fileDirectory + file + fileExtension, fileDirectory +file + \"-\" + str(year) + str(month) + fileExtension)\n",
    "\n",
    "# This 'config file' contains the variable definitions for all of the equipment names, \n",
    "# space names, column names for data, etc.  The most common reason for these scripts\n",
    "# to break is because something in LibCal has changed (the name of an item or space, question\n",
    "# responses in the booking forms (e.g. facuty name or relationship to institution), etc.\n",
    "# This import statement lets me keep all that stuff in a separate file.\n",
    "from libCalNames import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4947ffa-9b29-47a1-ae62-416004d98168",
   "metadata": {},
   "source": [
    "## Get a token for API acess\n",
    "\n",
    "By default, tokens are valid for one hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e45200f-7a6a-48e4-aa3b-57408b873331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs and data structures for API calls are all listed in the admin pages for the Libapps API module\n",
    "url = 'https://yorku.libcal.com/1.1/oauth/token'\n",
    "myRequestData = {'client_id': clientID,\n",
    "        'client_secret': clientSecret,\n",
    "        'grant_type': 'client_credentials'}\n",
    "\n",
    "# send the request\n",
    "call = requests.post(url, data = myRequestData)\n",
    "\n",
    "# API authorization is returned in a JSON object, and we need to grab/store our access token, which\n",
    "# is used to validate API calls for getting/setting data\n",
    "authorizationData = call.json()\n",
    "accessToken = authorizationData['access_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4614cd47-fff4-48cd-8c8f-cdd82927a071",
   "metadata": {},
   "source": [
    "## Send a request\n",
    "\n",
    "LibCal uses two different modules for Spaces and Equipment, and each has different API URLs. In this section we'll build API calls to pull one month's worth of data for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42c26f7-f9f4-4eb0-8fc0-beff8a0ed78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "equipURL = 'https://yorku.libcal.com/1.1/equipment/bookings'\n",
    "spaceURL = 'https://yorku.libcal.com/1.1/space/bookings'\n",
    "\n",
    "# NOTE for the following: the MAXIMUM record limit for the LibCal API is 500, meaning 500 rows of data. No issues currently, but in the future\n",
    "# this may become a problem that needs to be dealt with. A month that contains more than 500 records would have data truncated.\n",
    "# As of March 2023 (our busiest month so far jusged in summer of 2023) the equiopment booking list\n",
    "# had 415 entries... so the time of This Breaking is nigh at hand\n",
    "equipData = {'date': datadate,\n",
    "        'days': daysInMonth,\n",
    "        'limit': 500,\n",
    "        'lid': locationID,\n",
    "        'include_cancel': 1,\n",
    "        'formAnswers': 1}\n",
    "spaceData = {'date': datadate,\n",
    "        'lid': locationID,  \n",
    "        'days': daysInMonth,\n",
    "        'limit': 500,\n",
    "        'lid': locationID,\n",
    "        'include_cancel': 1,\n",
    "        'formAnswers': 1}\n",
    "\n",
    "headers = {'Authorization':'Bearer '+accessToken}\n",
    "\n",
    "# get Equipment module data for the month\n",
    "response = requests.get(equipURL, headers=headers, params=equipData)\n",
    "equipAPIData = response.json()\n",
    "\n",
    "# get Spaces module data for the month\n",
    "response = requests.get(spaceURL, headers=headers, params=spaceData)\n",
    "spacesAPIData = response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d9564-afa1-439d-82ab-6df9e5940cdd",
   "metadata": {},
   "source": [
    "## First-pass data cleaning (for raw CSV output)\n",
    "\n",
    "Some JSON values are EMPTY and this will result in misaligned columns of data in CSV output file near the end of the rows (where custom form question data is output).  We need to iterate through JSON data and replace any empy values in \"cancelled\", \"q2489\", \"q2490\" and \"q2491\" fields.  I'm using two loops, one for each data set, because their structures are different. I'm sure there's a more elgeant way to generalize this, but why get fancy if we don't need to?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9389f8c3-9d41-48cd-b31c-8c08f30d5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of field names for which data may be missing (due to booking form variations etc.\n",
    "# for example, if no \"cancellation\" of a booking occurred, there is no 'cancelled' data in the record.\n",
    "# This is mostly for space data. Equioment data only has \"cancelled\" as a possible missing field\n",
    "possiblyMissingFields = ['cancelled', 'q2579', 'q2669', 'seat_id', 'seat_name', 'check_in_code']\n",
    "\n",
    "# Basic cleaning for Equipment API data\n",
    "for entry in equipAPIData:\n",
    "    if \"cancelled\" in entry:\n",
    "        if entry['cancelled'] == \"\":\n",
    "            entry['cancelled'] = \"null\"\n",
    "    else:\n",
    "        entry[\"cancelled\"] = \"null\"\n",
    "     \n",
    "    # These are the custom questions, which are occasionally not filled out; \n",
    "    # empty questions result in mal-formatted CSV output so I set to null if nonexistent in a record\n",
    "    for customQKey in ['q2489','q2491', 'q2704', 'q2705', 'q2669', 'q2861', 'q2862', 'q2734', 'q2579', 'q3039', 'q3047','q3048']:\n",
    "        if (customQKey not in entry.keys()) or (entry[customQKey] == \"\"):\n",
    "            entry[customQKey] = \"null\"\n",
    "        \n",
    "    #Change key names for custom question fields\n",
    "    entry[\"relpToYork\"] = entry.pop(\"q2489\")\n",
    "    entry[\"project\"] = entry.pop(\"q2491\")\n",
    "    entry[\"VRexperience\"] = entry.pop(\"q2579\")\n",
    "    entry[\"groupBooking\"] = entry.pop(\"q2704\")\n",
    "    entry[\"groupSize\"] = entry.pop(\"q2705\")\n",
    "    entry[\"faculty\"] = entry.pop(\"q2734\")\n",
    "    entry[\"flexStudioUse\"] = entry.pop(\"q2669\")\n",
    "    entry[\"flexStudioPhotoCameraChoice\"] = entry.pop(\"q2862\")\n",
    "    entry[\"flexStudioVidCameraChoice\"] = entry.pop(\"q2861\")\n",
    "    entry[\"flexStudioBackgroundChoice\"] = entry.pop(\"q3039\")\n",
    "    entry.pop(\"q3047\")\n",
    "    entry.pop(\"q3048\")\n",
    "    \n",
    "    # Remove identifying patron information\n",
    "    entry.pop(\"firstName\") \n",
    "    entry.pop(\"lastName\")\n",
    "    entry.pop(\"account\")\n",
    "    entry[\"email\"] = hashlib.md5(entry[\"email\"].encode()).hexdigest()\n",
    "    \n",
    "\n",
    "    # Handle cases where the 'Other' field value might cause problems with stats (since it's a possible answer for\n",
    "    # two different questions on booking forms\n",
    "    if entry[\"relpToYork\"] == \"Other\": entry[\"relpToYork\"] = \"Other Relationship\" \n",
    "    if entry[\"faculty\"] == \"Other\": entry[\"faculty\"] = \"Other Faculty or No Faculty\"\n",
    "\n",
    "# Basic cleaning for Spaces API data\n",
    "for entry in spacesAPIData:\n",
    "    \n",
    "    # Go through list of 'possibly missing' fields to see if they're in the data; if so and empty,\n",
    "    # set to null. Without this, the output CSV file will be missing some fields and data won't line up with headers\n",
    "    for possiblyMissing in possiblyMissingFields:\n",
    "        if possiblyMissing in entry:\n",
    "            if str(entry[possiblyMissing]) == \"\":\n",
    "                entry[possiblyMissing] = \"null\"\n",
    "        else:\n",
    "            entry[possiblyMissing] = \"null\"\n",
    "\n",
    "    # These are the custom questions, which are occasionally not filled out; \n",
    "    # empty questions result in mal-formatted CSV output so I set to null if nonexistent in a record\n",
    "    for customQKey in ['q2489','q2491','q2491','q2669', 'q2704', 'q2705', 'q2861', 'q2862', 'q2734', 'q2579', 'q3039', 'q3047', 'q3048']:\n",
    "        if (customQKey not in entry.keys()) or (entry[customQKey] == \"\"):\n",
    "            entry[customQKey] = \"null\"\n",
    "    \n",
    "    #Change key names for custom question fields\n",
    "    entry[\"relpToYork\"] = entry.pop(\"q2489\")\n",
    "    entry[\"project\"] = entry.pop(\"q2491\")\n",
    "    entry[\"VRexperience\"] = entry.pop(\"q2579\")\n",
    "    entry[\"flexStudioUse\"] = entry.pop(\"q2669\")\n",
    "    entry[\"flexStudioPhotoCameraChoice\"] = entry.pop(\"q2862\")\n",
    "    entry[\"flexStudioVidCameraChoice\"] = entry.pop(\"q2861\")\n",
    "    entry[\"flexStudioBackgroundChoice\"] = entry.pop(\"q3039\")\n",
    "    entry[\"faculty\"] = entry.pop(\"q2734\")\n",
    "    entry[\"groupBooking\"] = entry.pop(\"q2704\")\n",
    "    entry[\"groupSize\"] = entry.pop(\"q2705\")\n",
    "    entry.pop(\"q3047\")\n",
    "    entry.pop(\"q3048\")\n",
    "    \n",
    "    # Remove identifying patron information\n",
    "    entry.pop(\"firstName\") \n",
    "    entry.pop(\"lastName\")\n",
    "    entry.pop(\"account\")\n",
    "    entry[\"email\"] = hashlib.md5(entry[\"email\"].encode()).hexdigest()\n",
    "    \n",
    "    # Handle cases where the 'Other' field value might cause problems with stats (since it's a possible answer for\n",
    "    # two different questions on booking forms\n",
    "    if entry[\"relpToYork\"] == \"Other\": entry[\"relpToYork\"] = \"Other Relationship\" \n",
    "    if entry[\"faculty\"] == \"Other\": entry[\"faculty\"] = \"Other Faculty or No Faculty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3abece26-941d-4d79-9aa5-4ab62d1a8e46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bookId': 'cs_Xg41Zmu3', 'id': 8996655, 'eid': 19904, 'cid': 6842, 'lid': 2632, 'fromDate': '2024-05-30T14:00:00-04:00', 'toDate': '2024-05-30T16:10:00-04:00', 'created': '2024-05-21T18:57:11-04:00', 'email': '471f5364145667650dad6fed5483a6f7', 'status': 'Mediated Approved', 'location_name': 'Scott Media Creation Lab', 'category_name': 'Flex Studio Spaces', 'item_name': '204 Flex Studio', 'event': None, 'check_in_code': 'E34', 'cancelled': 'null', 'seat_id': 'null', 'seat_name': 'null', 'relpToYork': 'Undergraduate Student', 'project': 'Women in Law Podcast ', 'VRexperience': 'null', 'flexStudioUse': 'Podcasting (Audio and Video)', 'flexStudioPhotoCameraChoice': 'null', 'flexStudioVidCameraChoice': 'null', 'flexStudioBackgroundChoice': 'Black', 'faculty': 'Health (HH)', 'groupBooking': 'null', 'groupSize': 'null'}\n"
     ]
    }
   ],
   "source": [
    "print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb579f7-28c6-4b07-a4fc-bd5e27852f6c",
   "metadata": {},
   "source": [
    "## Writing Data to a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f734af3-16b9-43f3-b208-d2665c4bc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## OUTPUT: Equipment data\n",
    "\n",
    "csvOut = open(\"data/\"+datadate+\"_equip.csv\", 'w')\n",
    "\n",
    "# create the csv writer object\n",
    "csv_writer = csv.DictWriter(csvOut, fieldnames=equipInputDataFieldnames)\n",
    "\n",
    "# Output the header first\n",
    "csv_writer.writeheader()\n",
    " \n",
    "for record in equipAPIData:\n",
    "    csv_writer.writerow(record)\n",
    " \n",
    "csvOut.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## OUTPUT: Space data\n",
    "\n",
    "csvOut = open(\"data/\"+datadate+\"_space.csv\", 'w')\n",
    "\n",
    "# create the csv writer object\n",
    "csv_writer = csv.DictWriter(csvOut, fieldnames=spacesInputDataFieldnames)\n",
    "\n",
    "# Output the header first\n",
    "csv_writer.writeheader()\n",
    "\n",
    "for record in spacesAPIData:\n",
    "    csv_writer.writerow(record)\n",
    " \n",
    "csvOut.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9714cd1-ef48-4e4e-85e6-c90c97998884",
   "metadata": {},
   "source": [
    "## Pull in CSV data for final processing \n",
    "\n",
    "_(AND/OR convert the data to DataFrames, the code for which was added in June 2023 but has not yet been tested in ANY way)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a1fe4c-4cbc-497a-871b-a29d2bb23951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hey, so those files we literally just created? Let's read 'em into Pandas Dataframes! \n",
    "# Why is this so obtuse, you ask?\n",
    "# Because this was originally a separate script and I should consider converting the dict from earlier \n",
    "# in THIS script into a DataFrame but TBH I think the raw CSV files are still valuable and so this is ok by me\n",
    "\n",
    "# Anyway, since we built the CSV files in the previous step, the format of them should be reliable \n",
    "# and we can simply read them into Pandas\n",
    "\n",
    "spacesData = pd.read_csv(\"data/\"+datadate+\"_space.csv\", index_col='id')\n",
    "equipData = pd.read_csv(\"data/\"+datadate+\"_equip.csv\", index_col='id')\n",
    "\n",
    "\n",
    "###\n",
    "### FOR FUTURE WORK: to convert a list to DataFrame without doing the CSV interim step, use\n",
    "### this pattern:\n",
    "###\n",
    "###     import pandas as pd\n",
    "###     list_name = ['item_1', 'item_2', 'item_3', ...]\n",
    "###     df = pd.DataFrame(list_name, columns=['column_name'])\n",
    "###\n",
    "### CONVERT Spaces data to DataFrame (ADDED JUNE 2023 but NOT TESTED...)\n",
    "# spacesData = pd.DataFrame(spacesAPIData, columns=['spacesInputDataFieldnames'])\n",
    "###\n",
    "### CONVERT Equipment data to DataFrame (ADDED JUNE 2023 but NOT TESTED...)\n",
    "# equipData = pd.DataFrame(equipAPIData, columns=['equipInputDataFieldnames'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57512ff0-070f-4701-9825-ace616a47bc2",
   "metadata": {},
   "source": [
    "# Metrics and Stats Processing\n",
    "\n",
    "## Cancelled vs Actual Bookings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05b64537-86f2-4554-b9cc-a1087b55738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPACES DATA\n",
      "Total bookings made: 86\n",
      "Cancelled by users: 20\n",
      "Cancelled for late checkin: 10\n",
      "Cancelled by staff: 6\n",
      "Total actual bookings: 50\n",
      "\n",
      "EQUIPMENT DATA\n",
      "Total bookings made: 348\n",
      "Cancelled by users: 26\n",
      "Cancelled for late checkin: 52\n",
      "Cancelled by staff: 28\n",
      "Total actual bookings: 242\n"
     ]
    }
   ],
   "source": [
    "# Drop staff-affiliated bookings right off the top, so numbers all match; \n",
    "# otherwise the counts of cancellations, etc. get thrown off\n",
    "for address in adminEmails:\n",
    "    spacesData.drop(spacesData.index[(spacesData[\"email\"] == address)],axis=0,inplace=True)\n",
    "    equipData.drop(equipData.index[(equipData[\"email\"] == address)],axis=0,inplace=True)\n",
    "\n",
    "# Grab a Series of just Status Column\n",
    "spacesBookingStatus = spacesData[\"status\"]\n",
    "equipmentBookingStatus = equipData[\"status\"]\n",
    "\n",
    "# How many do we have? DO counts of all of the relevant data fields\n",
    "spacesOutputData[\"totalBookings\"] = len(spacesBookingStatus)\n",
    "equipmentOutputData[\"totalBookings\"] = len(equipmentBookingStatus)\n",
    "\n",
    "spacesOutputData[\"cancelledByUsers\"] = len(spacesBookingStatus[spacesBookingStatus.str.startswith('Cancelled by User')])\n",
    "equipmentOutputData[\"cancelledByUsers\"] = len(equipmentBookingStatus[equipmentBookingStatus.str.startswith('Cancelled by User')])\n",
    "\n",
    "spacesOutputData[\"cancelledBySystem\"] = len(spacesBookingStatus[spacesBookingStatus.str.startswith('Cancelled by System')])\n",
    "equipmentOutputData[\"cancelledBySystem\"] = len(equipmentBookingStatus[equipmentBookingStatus.str.startswith('Cancelled by System')])\n",
    "\n",
    "spacesOutputData[\"cancelledByAdmin\"] = len(spacesBookingStatus[spacesBookingStatus.str.startswith('Cancelled by Admin')])\n",
    "equipmentOutputData[\"cancelledByAdmin\"] = len(equipmentBookingStatus[equipmentBookingStatus.str.startswith('Cancelled by Admin')])\n",
    "\n",
    "spacesOutputData[\"totalActualBookings\"] = spacesOutputData[\"totalBookings\"]-spacesOutputData[\"cancelledByUsers\"]-spacesOutputData[\"cancelledBySystem\"]-spacesOutputData[\"cancelledByAdmin\"]\n",
    "equipmentOutputData[\"totalActualBookings\"] = equipmentOutputData[\"totalBookings\"]-equipmentOutputData[\"cancelledByUsers\"]-equipmentOutputData[\"cancelledBySystem\"]-equipmentOutputData[\"cancelledByAdmin\"]\n",
    "\n",
    "\n",
    "print(\"SPACES DATA\")\n",
    "print(\"Total bookings made:\", spacesOutputData[\"totalBookings\"])\n",
    "print(\"Cancelled by users:\", spacesOutputData[\"cancelledByUsers\"]) \n",
    "print(\"Cancelled for late checkin:\", spacesOutputData[\"cancelledBySystem\"])\n",
    "print(\"Cancelled by staff:\", spacesOutputData[\"cancelledByAdmin\"])\n",
    "print(\"Total actual bookings:\", spacesOutputData[\"totalActualBookings\"])\n",
    "print()\n",
    "print(\"EQUIPMENT DATA\")\n",
    "print(\"Total bookings made:\", equipmentOutputData[\"totalBookings\"])\n",
    "print(\"Cancelled by users:\", equipmentOutputData[\"cancelledByUsers\"]) \n",
    "print(\"Cancelled for late checkin:\", equipmentOutputData[\"cancelledBySystem\"])\n",
    "print(\"Cancelled by staff:\", equipmentOutputData[\"cancelledByAdmin\"])\n",
    "print(\"Total actual bookings:\", equipmentOutputData[\"totalActualBookings\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30314bc-178b-4ba4-86b7-a228dc119f76",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DROPPING UNWANTED DATA\n",
    "\n",
    "Drop rows where bookings have been cancelled (by the user; by a staff member; by the system due to late checkin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c54a0fbf-f22b-419f-96b5-829a51df798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop bookings canceled by User and by System\n",
    "spacesData.drop(spacesData.index[(spacesData[\"status\"] == 'Cancelled by User')],axis=0,inplace=True)\n",
    "equipData.drop(equipData.index[(equipData[\"status\"] == 'Cancelled by User')],axis=0,inplace=True)\n",
    "\n",
    "spacesData.drop(spacesData.index[(spacesData[\"status\"] == 'Cancelled by System')],axis=0,inplace=True)\n",
    "equipData.drop(equipData.index[(equipData[\"status\"] == 'Cancelled by System')],axis=0,inplace=True)\n",
    "\n",
    "spacesData.drop(spacesData.index[(spacesData[\"status\"].str.startswith('Cancelled by Admin'))],axis=0,inplace=True)\n",
    "equipData.drop(equipData.index[(equipData[\"status\"].str.startswith('Cancelled by Admin'))],axis=0,inplace=True)\n",
    "\n",
    "#spacesData.drop(spacesData.index[(spacesData[\"cid\"].str.startswith('6212'))],axis=0,inplace=True)\n",
    "#equipData.drop(equipData.index[(equipData[\"cid\"].str.startswith('6212'))],axis=0,inplace=True)\n",
    "spacesData.drop(spacesData.loc[spacesData['cid']==6212].index, axis=0, inplace=True)\n",
    "equipData.drop(equipData.loc[equipData['cid']==6212].index, axis=0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b5085-431e-4d86-83f2-77ad53389366",
   "metadata": {},
   "source": [
    "## Data: Unique projects, VR content choices, and Flex Studio uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57727099-4301-4082-bb73-1e29f81e755b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equipment projects: 'an video for business project ' 'YouTube Podcast ' 'social media ' 'Audio testing' 'Testing Audio' 'Student Training Video' 'Photography Project' 'Personal Project' 'Private event' 'Content Creating' 'Recording event' 'Virtual Reality and Metaverse' 'Video creation' 'Personal Dance Project to gain self-confidence' 'Headshots' 'sports media' 'personal' 'Own project.' 'Own project' 'CMDS1000 Screenfast Remediated' 'Soundings ' 'FA VISA 2065' 'Training' 'training' 'Personal Project (training)' 'Faculy of Health Videos' 'Library Project' 'Personal' 'Meetings' 'Test shooting for a photography project' 'Song recording' 'Project' 'Social Media Content' 'Social Media content' 'Journalism interviews' 'Recruitment promotion video' 'Recruitment promotion' 'Sound Art Project' 'documentary' 'Research video' 'Photography ' 'Shoot' 'Shooy' 'DJ practicing ' 'teaching' 'Casual photography' 'personal documentary' 'Student Film' 'Experimental Feature Film' 'Psychology' 'Creative content ' 'Creative Content ' 'CMA 1120 Final Project' 'Film 1020' 'Personal use ' 'taking professional pictures ' 'Taking professional pictures and videos' 'Movie' 'movie' 'Assignment ' 'School' 'Event photography' \"Testing for Master's Research Project Proposal\" 'personal project' 'Podcasting ' 'C4' 'MRP' 'Library work' 'Modelling Shoot' 'Content creation ' 'C4 video' 'Documentary Project' 'Psychology project' 'Master thesis' 'Social media video' 'Video Shoot for Faculty of Health' 'Church production ' 'Personal Project (requires 2 cameras - club activity)' 'Personal Project ' 'Film Project' 'Music' 'Summer school project ' 'Personal project ' 'I would love to borrow for the event of my club. ' 'Personal project' 'Personal Work'\n",
      "Number of unique equipment projects: 86\n",
      "\n",
      "Spaces projects: 'Women in Law Pocast' 'A short film' 'I want to test out the recording studio' 'Women in Law Podcast ' 'personal project' 'CLTR2860 podcast' 'School Project' 'Soundings' 'Content Creation - Podcasting' 'Taking Photos for a Club, The Photographer is a Image Arts Student from Toronto Metropolitan University' 'Personal Project' 'Journalism interviews' 'Audio Drama' 'Training' 'audio drama' 'Radio Play Podcast ' 'Personal' 'Podcast' 'MRP' 'Markham MCL Training' 'Work Podcast' 'C4 video' 'podcast' 'C4 Video'\n",
      "Number of unique spaces projects: 24\n",
      "\n",
      "Flex Studio projects: 'Podcasting (Audio and Video)'  'Photography (General)' 'Podcasting (Audio Only)' 'Video Recording (General)' 'Audio Recording'\n",
      "VR Room experiences: \n"
     ]
    }
   ],
   "source": [
    "# Set up a string translation table to remove newline characters from \"project\" entry fields\n",
    "# Since the string is built by casting a LIST as a STRING, we can also remove\n",
    "# the [ and ] characters that Python would use to show the sdata is in a list\n",
    "strTranslation = str.maketrans('', '' ,'\\r\\n[]')\n",
    "\n",
    "# First we can grab project field data and calculate the number of \"unique\" projects found within it\n",
    "spacesOutputData[\"uniqueProjects\"] = len(spacesData['project'].unique())-1\n",
    "spacesOutputData[\"projectList\"] = str(spacesData['project'].unique()).replace(\"nan \",\"\") #remove Pandas NaN values from the string\n",
    "spacesOutputData[\"projectList\"] = spacesOutputData[\"projectList\"].translate(strTranslation)\n",
    "\n",
    "equipmentOutputData[\"uniqueProjects\"] = len(equipData['project'].unique())-1\n",
    "equipmentOutputData[\"projectList\"] = str(equipData['project'].unique()).replace(\"nan \",\"\") #remove Pandas NaN values from the string\n",
    "equipmentOutputData[\"projectList\"] = equipmentOutputData[\"projectList\"].translate(strTranslation)\n",
    "\n",
    "# Users also provide info on how they'll use the Flex Studio or VR Rooms as part of those forms, so grab that...\n",
    "spacesOutputData[\"VRContentList\"] = str(spacesData['VRexperience'].unique()).replace(\"nan\",\"\") #remove Pandas NaN values from the string\n",
    "spacesOutputData[\"VRContentList\"] = spacesOutputData[\"VRContentList\"].translate(strTranslation)\n",
    "spacesOutputData[\"flexStudioUseList\"] = str(spacesData['flexStudioUse'].unique()).replace(\"nan\",\"\") #remove Pandas NaN values from the string\n",
    "spacesOutputData[\"flexStudioUseList\"] = spacesOutputData[\"flexStudioUseList\"].translate(strTranslation)\n",
    "\n",
    "print(\"Equipment projects:\", equipmentOutputData[\"projectList\"])\n",
    "print(\"Number of unique equipment projects:\", equipmentOutputData[\"uniqueProjects\"])\n",
    "print()\n",
    "print(\"Spaces projects:\", spacesOutputData[\"projectList\"])\n",
    "print(\"Number of unique spaces projects:\", spacesOutputData[\"uniqueProjects\"])\n",
    "print()\n",
    "print(\"Flex Studio projects:\", spacesOutputData[\"flexStudioUseList\"])\n",
    "print(\"VR Room experiences:\", spacesOutputData[\"VRContentList\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab6420-192b-4b05-b7c5-a767aec8aed9",
   "metadata": {},
   "source": [
    "## Data: Frequencies / Counts for faculty, RTI, space categories and equipment categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7865132-8a17-45aa-a7de-218a1149b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both the equipment and spaces data have info for faculty, RTI, space/equipment category and item, so we'll\n",
    "# look through those to build tallies and store them in the output data\n",
    "for category in [\"faculty\", \"relpToYork\", \"category_name\", 'item_name']:\n",
    "    spacesCategoryTallies = spacesData[category].value_counts(dropna=True).to_dict()\n",
    "    equipmentCategoryTallies = equipData[category].value_counts(dropna=True).to_dict()\n",
    "    for key in spacesCategoryTallies:\n",
    "        spacesOutputData[key] = spacesCategoryTallies[key]\n",
    "    for key in equipmentCategoryTallies:\n",
    "        equipmentOutputData[key] = equipmentCategoryTallies[key]    \n",
    "\n",
    "# The Spaces data has a unique \"seat_name\" category so we'll do this one separately...\n",
    "workstationTallies = spacesData[\"seat_name\"].value_counts(dropna=True).to_dict()\n",
    "for key in workstationTallies:\n",
    "    spacesOutputData[key] = workstationTallies[key]     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b07a0-d2c8-45e0-953a-4cf658b1354f",
   "metadata": {},
   "source": [
    "## Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1c50562-8e16-468f-b037-1b4cdedee3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique space users: 27\n",
      "Number of unique equipment users: 74\n"
     ]
    }
   ],
   "source": [
    "# We can count unique users by looking at unique email addresses. As a note, I have seen that some students will\n",
    "# use more than one address when booking, which makes one person appear as two (or three).... not sure there's\n",
    "# much to be done about this\n",
    "spacesOutputData[\"uniqueUsers\"] = len(spacesData['email'].unique())\n",
    "equipmentOutputData[\"uniqueUsers\"] = len(equipData['email'].unique())\n",
    "\n",
    "print(\"Number of unique space users:\", spacesOutputData[\"uniqueUsers\"])\n",
    "print(\"Number of unique equipment users:\", equipmentOutputData[\"uniqueUsers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7057fd1-f2e3-4af4-88a3-fda89f4cc88d",
   "metadata": {},
   "source": [
    "## User access times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc3ac7b7-c22a-4352-9e18-470e03d1f7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11AM 14\n",
      "02PM 6\n",
      "03PM 4\n",
      "05PM 1\n",
      "12PM 6\n",
      "01PM 6\n",
      "04PM 2\n",
      "Wednesday 12\n",
      "Thursday 8\n",
      "Sunday 4\n",
      "Monday 7\n",
      "Tuesday 8\n",
      "11AM 27\n",
      "01PM 11\n",
      "02PM 25\n",
      "04PM 14\n",
      "09AM 3\n",
      "03PM 23\n",
      "12PM 21\n",
      "05PM 1\n",
      "Monday 16\n",
      "Wednesday 33\n",
      "Thursday 34\n",
      "Tuesday 28\n",
      "Sunday 7\n",
      "Friday 7\n"
     ]
    }
   ],
   "source": [
    "# the fromDate field is used in both modules to log the time a user checks out a piece of equipment OR checks in to a space\n",
    "# In this section we'll run througb that data and pull out frequences by day of the week and hour of the day\n",
    "spacesCheckInTimes = spacesData['fromDate'].unique()\n",
    "spacesCheckInTimes = spacesCheckInTimes.tolist()\n",
    "\n",
    "equipCheckInTimes = equipData['fromDate'].unique()\n",
    "equipCheckInTimes = equipCheckInTimes.tolist()\n",
    "\n",
    "# Run through each of the checkin times lists to steip out day and hour info, and populate\n",
    "# the outputData structures for ewach of the equipment and spaces categories\n",
    "for reportType in [spacesCheckInTimes, equipCheckInTimes]:\n",
    "    \n",
    "    #initialize array for hours-only data\n",
    "    checkInHours = []\n",
    "    checkInDays = []\n",
    "\n",
    "    # Convert HH:MM info strings into hours                                    \n",
    "    for entry in reportType:\n",
    "        if isinstance(entry, str) == True:\n",
    "            accessTime = datetime.strptime(entry, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "            # Need to handle an case where bookings are added manually, in which\n",
    "            # case the time is set to midnight. For now alter this to read 10AM (lab opening time)\n",
    "            if accessTime.strftime(\"%I%p\") == \"12AM\":\n",
    "                checkInHours.append(accessTime.strftime(\"10AM\"))\n",
    "            else:\n",
    "                checkInHours.append(accessTime.strftime(\"%I%p\"))        \n",
    "            checkInDays.append(accessTime.strftime(\"%A\"))\n",
    "\n",
    "    # set up a Counter object to do frequency counts for checking times (total for whole month)\n",
    "    checkInHoursCount = collections.Counter(checkInHours)\n",
    "    checkInDaysCount = collections.Counter(checkInDays)\n",
    "\n",
    "    for item in [checkInHoursCount, checkInDaysCount]:\n",
    "\n",
    "        # Store totals in our outputData\n",
    "        for key, value in item.items():\n",
    "            if reportType == spacesCheckInTimes:\n",
    "                spacesOutputData[key] = value\n",
    "                print(key, spacesOutputData[key])\n",
    "            else:\n",
    "                equipmentOutputData[key] = value\n",
    "                print(key, equipmentOutputData[key])\n",
    "            #print(f\"{key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e938b23-c942-4cc0-aacc-5a78cdccf321",
   "metadata": {},
   "source": [
    "## Data: First Time Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23f8dd49-cd17-4f34-add0-01e612fa41eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This month's number of new space users: 16\n",
      "This month's number of new equipment users: 30\n",
      "This month's number of new overall users: 42\n"
     ]
    }
   ],
   "source": [
    "spacesOutputData[\"firstTimeUsers\"] = 0\n",
    "equipmentOutputData[\"firstTimeUsers\"] = 0\n",
    "overallFirstTimeUsers = 0\n",
    "\n",
    "# Read existing data files and build user lists\n",
    "existingSpaceUserFile = open(\"data/existingSpaceUsers.txt\", \"r\")\n",
    "existingEquipmentUserFile = open(\"data/existingEquipmentUsers.txt\", \"r\")\n",
    "existingOverallUserFile = open(\"data/existingOverallUsers.txt\", \"r\")\n",
    "\n",
    "existingSpaceUserDataSet = existingSpaceUserFile.read()\n",
    "existingSpaceUsers = existingSpaceUserDataSet.split(\"\\n\")\n",
    "\n",
    "existingEquipmentUserDataSet = existingEquipmentUserFile.read()\n",
    "existingEquipmentUsers = existingEquipmentUserDataSet.split(\"\\n\")\n",
    "\n",
    "existingOverallUserDataSet = existingOverallUserFile.read()\n",
    "existingOverallUsers = existingOverallUserDataSet.split(\"\\n\")\n",
    "\n",
    "# Get a list of unique users for this month\n",
    "spaceUniqueUsers = spacesData['email'].unique()\n",
    "spaceUniqueUsers = spaceUniqueUsers.tolist()\n",
    "\n",
    "equipUniqueUsers = equipData['email'].unique()\n",
    "equipUniqueUsers = equipUniqueUsers.tolist()\n",
    "\n",
    "overallUniqueUsers = list(set(spaceUniqueUsers + equipUniqueUsers))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for usergroup in [spaceUniqueUsers, equipUniqueUsers, overallUniqueUsers]:\n",
    "\n",
    "    for userThisMonth in usergroup:\n",
    "\n",
    "        # make a hash of the email address so we don't have text files full of plaintext addresses\n",
    "        # NOTE: no longer needed if all emakil addressed are hashed in \"raw\" CSV output\n",
    "        #userThisMonth = hashlib.md5(userThisMonth.encode()).hexdigest()\n",
    "        \n",
    "        if usergroup == spaceUniqueUsers:\n",
    "            if userThisMonth not in existingSpaceUsers:\n",
    "                spacesOutputData[\"firstTimeUsers\"] += 1\n",
    "                existingSpaceUsers.append(userThisMonth)\n",
    "        elif usergroup == equipUniqueUsers:\n",
    "            if userThisMonth not in existingEquipmentUsers:\n",
    "                equipmentOutputData[\"firstTimeUsers\"] += 1\n",
    "                existingEquipmentUsers.append(userThisMonth)\n",
    "        else:\n",
    "            if userThisMonth not in existingOverallUsers:\n",
    "                overallFirstTimeUsers += 1\n",
    "                existingOverallUsers.append(userThisMonth)\n",
    "        \n",
    "existingOverallUsers = list(set(existingSpaceUsers + existingEquipmentUsers))  \n",
    "\n",
    "# Dump the new existing user lists back to a file\n",
    "with open(\"data/existingSpaceUsers.txt\", \"w\") as existingSpaceUserFile:\n",
    "    existingSpaceUserDataSet = \"\\n\".join(existingSpaceUsers)\n",
    "    existingSpaceUserFile.write(existingSpaceUserDataSet)\n",
    "\n",
    "with open(\"data/existingEquipmentUsers.txt\", \"w\") as existingEquipmentUserFile:\n",
    "    existingEquipmentUserDataSet = \"\\n\".join(existingEquipmentUsers)\n",
    "    existingEquipmentUserFile.write(existingEquipmentUserDataSet)\n",
    "    \n",
    "with open(\"data/existingOverallUsers.txt\", \"w\") as existingOverallUserFile:\n",
    "    existingOverallUserDataSet = \"\\n\".join(existingOverallUsers)\n",
    "    existingOverallUserFile.write(existingOverallUserDataSet)\n",
    "\n",
    "print(\"This month's number of new space users:\", spacesOutputData[\"firstTimeUsers\"])\n",
    "print(\"This month's number of new equipment users:\", equipmentOutputData[\"firstTimeUsers\"])\n",
    "print(\"This month's number of new overall users:\", overallFirstTimeUsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6775575c-54a5-4794-92aa-df51938481db",
   "metadata": {},
   "source": [
    "## Final Data Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f18f102-d5c9-4cdc-aa0b-003b49ecf569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will open a file for writing\n",
    "spaceCsvOut = open(\"data/\"+datadate+\"_space_finalStats.csv\", 'w')\n",
    "equipmentCsvOut = open(\"data/\"+datadate+\"_equipment_finalStats.csv\", 'w')\n",
    "\n",
    "# create the csv writer object\n",
    "spaceCsvWriter = csv.DictWriter(spaceCsvOut, fieldnames=spacesFinalFieldnames)\n",
    "equipmentCsvWriter = csv.DictWriter(equipmentCsvOut, fieldnames=equipmentFinalFieldnames)\n",
    "\n",
    "# Output the header first\n",
    "spaceCsvWriter.writeheader()\n",
    "equipmentCsvWriter.writeheader()\n",
    "\n",
    "spaceCsvWriter.writerow(spacesOutputData)\n",
    "equipmentCsvWriter.writerow(equipmentOutputData)\n",
    "\n",
    "spaceCsvOut.close()\n",
    "equipmentCsvOut.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9930bb-45cb-43c1-b83d-a9ea191e5b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d7d8d-c0cb-4375-8a38-b17746bd11cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ea5f3-ed25-4f48-af11-218b115a3b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
